{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Continual Anomaly Detection Experiments\n",
    "\n",
    "---\n",
    "\n",
    "### Datasets\n",
    "\n",
    "We have 2 datasets, MVTec-AD for benchmarking the traditional continual learning methods under the usual framework, where each category/object is its own task, and MTD, which contains one object type, Magnetic Tile Defects.\n",
    "\n",
    "The magnetic tiles have 5 different kinds of defects, and we will use this dataset to test out how benchmark methods perform in a continous data drift scenario. We will run several experiments on the MTD dataset, where each experiment will have _T_ tasks. The tasks will be progressive disruptions to the image at increasing intensity levels. \n",
    "\n",
    "For example, let's say we have an experiment where we see how increasing color jittering (adjusting brightness, saturationm and contrast) over time can be detected accurately, and color jitter can be on an intensity scale of [0, 1]. For task 1, we might jitter the color of images only at intensities within the windowed interval [0, 0.1]. For task 2, we might increase this window to [0, 0.2], and so on. We will be experimenting with different window sizes and whether they overlap or not, and we will save the dataset from our final reported results.\n",
    "\n",
    "### Experiments\n",
    "\n",
    "Under a general Continual Learning framework, we assume that a model will experience a series of tasks, where tasks are learned/adapted to one at a time and then tested after learning each task on all previous tasks. \n",
    "\n",
    "We will run an experiment to benchmark methods under the current general framework, which uses MVTec-AD and assumes that each category/object is its own task. This is the simplest experiment and is generally used in current literature, in some form or another. This task should be the simplest, because each category has a completely different pixel distribution space. \n",
    "\n",
    "For the different disruption types on MTD, we are running an experiment for each type of image distortion:\n",
    "- __Color Jitter__, which simulates lighting/color changes\n",
    "- __Blur__, which applies Gaussian Blur and simulates sensor wear or sensor out of focus\n",
    "- __Geometric__, which applies a mixture of rotation, translation, and shear to simulate product movement or deformation\n",
    "\n",
    "Again, the idea for these next experiments is that each task will have a similar or overlapping image pixel space, and we can test how well each method learns tasks in a continuous drift manner."
   ],
   "id": "86a85e95d262040c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T16:07:18.323048Z",
     "start_time": "2025-07-09T16:07:15.030365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Methods.IUF.iuf import IUF_Model\n",
    "from Methods.DNE.dne import DNE_Model\n",
    "from utils.train import train_model\n",
    "from utils.eval import eval_model\n",
    "import torch\n",
    "\n",
    "# Hyperparameters for training/testing\n",
    "torch.manual_seed(42)\n",
    "# Whether to do training, with which models, and on which datasets\n",
    "TRAIN = False\n",
    "EVAL = True\n",
    "models = {\n",
    "    \"DNE\":True,\n",
    "    \"IUF\":False,\n",
    "    \"UCAD\":False\n",
    "}\n",
    "datasets = {\n",
    "    \"MVTEC\":True,\n",
    "    \"MTD\":True\n",
    "}\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 24\n",
    "LEARNING_RATE = 0.00025\n",
    "\n",
    "data_aug = {\n",
    "    \"color\": [\n",
    "        [0.20, 0.26],\n",
    "        [0.26, 0.32],\n",
    "        [0.32, 0.38],\n",
    "        [0.38, 0.44],\n",
    "        [0.44, 0.50],\n",
    "        [0.50, 0.56],\n",
    "        [0.56, 0.62],\n",
    "        [0.62, 0.68],\n",
    "        [0.68, 0.74],\n",
    "        [0.74, 0.80]\n",
    "    ],\n",
    "    \"blur\": [\n",
    "        [1, 0.5],\n",
    "        [3, 1],\n",
    "        [5, 1.5],\n",
    "        [7, 2],\n",
    "        [9, 2.5],\n",
    "        [11, 3],\n",
    "        [13, 3.5],\n",
    "        [15, 4],\n",
    "        [17, 4.5],\n",
    "        [19, 5],\n",
    "    ],\n",
    "    \"geometric\": [\n",
    "        [4, 2, 0.02, 4],\n",
    "        [8, 4, 0.04, 8],\n",
    "        [12, 6, 0.06, 12],\n",
    "        [16, 8, 0.08, 16],\n",
    "        [20, 10, 0.10, 20],\n",
    "        [24, 12, 0.12, 24],\n",
    "        [28, 14, 0.14, 28],\n",
    "        [32, 16, 0.16, 32],\n",
    "        [36, 18, 0.18, 36],\n",
    "        [40, 20, 0.2, 40]\n",
    "    ]\n",
    "}\n",
    "# Running Training Experiments\n",
    "if TRAIN:\n",
    "    for model in models.keys():\n",
    "        if models[model]:\n",
    "            if datasets['MVTEC']:\n",
    "                train_model(model_type=model,\n",
    "                            dataset='MVTEC',\n",
    "                            num_epochs=NUM_EPOCHS,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            criterion=torch.nn.CrossEntropyLoss(),\n",
    "                            learning_rate=LEARNING_RATE\n",
    "                            )\n",
    "            elif datasets['MTD']:\n",
    "                for distortion in data_aug.keys():\n",
    "                    train_model(model_type=model,\n",
    "                                dataset='MTD',\n",
    "                                num_epochs=NUM_EPOCHS,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                criterion=torch.nn.CrossEntropyLoss(),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                tasks=data_aug[distortion],\n",
    "                                data_aug=distortion\n",
    "                                )\n",
    "\n",
    "# Running Evaluation Experiments\n",
    "if EVAL:\n",
    "    for model in models.keys():\n",
    "        if models[model]:\n",
    "            out = eval_model(model_type=model,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               data_aug=data_aug\n",
    "                               )"
   ],
   "id": "a850d1c85d6a2bfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/DNE/DNE_MTD_color_unsupervised_weights.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 91\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m models.keys():\n\u001B[32m     90\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m models[model]:\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m         out = \u001B[43meval_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[43m                           \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     93\u001B[39m \u001B[43m                           \u001B[49m\u001B[43mdata_aug\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata_aug\u001B[49m\n\u001B[32m     94\u001B[39m \u001B[43m                           \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PhD_Projects\\Continual_Anomaly_Detection\\utils\\eval.py:110\u001B[39m, in \u001B[36meval_model\u001B[39m\u001B[34m(model_type, batch_size, **kwargs)\u001B[39m\n\u001B[32m    108\u001B[39m     \u001B[38;5;28;01mcase\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mUCAD\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    109\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m110\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./models/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel_type\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel_type\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdataset\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdistortion\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[33;43munsupervised\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[43munsupervised\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msupervised\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_weights.pth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    112\u001B[39m \u001B[38;5;66;03m# If DNE, we need to generate our global distribution for inference\u001B[39;00m\n\u001B[32m    113\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_type == \u001B[33m\"\u001B[39m\u001B[33mDNE\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PhD_Projects\\Continual_Anomaly_Detection\\Methods\\DNE\\dne.py:345\u001B[39m, in \u001B[36mDNE_Model.load\u001B[39m\u001B[34m(self, model_path)\u001B[39m\n\u001B[32m    336\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    337\u001B[39m \u001B[33;03mLoads a model from a file, as well as memory\u001B[39;00m\n\u001B[32m    338\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    342\u001B[39m \n\u001B[32m    343\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# Load model dict, based on BaseAnomalyDetector\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m345\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[38;5;66;03m# Find memory path and load that as well\u001B[39;00m\n\u001B[32m    348\u001B[39m memory_path = model_path.split(\u001B[33m\"\u001B[39m\u001B[33mweights\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m0\u001B[39m] + \u001B[33m\"\u001B[39m\u001B[33mmemory.pth\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PhD_Projects\\Continual_Anomaly_Detection\\Methods\\__init__.py:134\u001B[39m, in \u001B[36mBaseAnomalyDetector.load\u001B[39m\u001B[34m(self, path)\u001B[39m\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload\u001B[39m(\u001B[38;5;28mself\u001B[39m, path):\n\u001B[32m    129\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    130\u001B[39m \u001B[33;03m    Loads the model from disk.\u001B[39;00m\n\u001B[32m    131\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m    132\u001B[39m \u001B[33;03m        path: path to load the model from.\u001B[39;00m\n\u001B[32m    133\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m     \u001B[38;5;28mself\u001B[39m.load_state_dict(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    135\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniforge3\\Lib\\site-packages\\torch\\serialization.py:1425\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[39m\n\u001B[32m   1422\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args.keys():\n\u001B[32m   1423\u001B[39m     pickle_load_args[\u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1425\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[32m   1426\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[32m   1427\u001B[39m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[32m   1428\u001B[39m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[32m   1429\u001B[39m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[32m   1430\u001B[39m         orig_position = opened_file.tell()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniforge3\\Lib\\site-packages\\torch\\serialization.py:751\u001B[39m, in \u001B[36m_open_file_like\u001B[39m\u001B[34m(name_or_buffer, mode)\u001B[39m\n\u001B[32m    749\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[32m    750\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[32m--> \u001B[39m\u001B[32m751\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    752\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    753\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniforge3\\Lib\\site-packages\\torch\\serialization.py:732\u001B[39m, in \u001B[36m_open_file.__init__\u001B[39m\u001B[34m(self, name, mode)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: './models/DNE/DNE_MTD_color_unsupervised_weights.pth'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T15:31:14.013010Z",
     "start_time": "2025-07-09T15:31:14.001025Z"
    }
   },
   "cell_type": "code",
   "source": "out",
   "id": "112e801acc282839",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [color_02_026, color_026_032, color_032_038, color_038_044, color_044_05, color_05_056, color_056_062, color_062_068, color_068_074, color_074_08, blur_1_05, blur_3_1, blur_5_15, blur_7_2, blur_9_25, blur_11_3, blur_13_35, blur_15_4, blur_17_45, blur_19_5, geometric_42_002_4, geometric_84_004_8, geometric_126_006_12, geometric_168_008_16, geometric_2010_01_20, geometric_2412_012_24, geometric_2814_014_28, geometric_3216_016_32, geometric_3618_018_36, geometric_4020_02_40]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_02_026</th>\n",
       "      <th>color_026_032</th>\n",
       "      <th>color_032_038</th>\n",
       "      <th>color_038_044</th>\n",
       "      <th>color_044_05</th>\n",
       "      <th>color_05_056</th>\n",
       "      <th>color_056_062</th>\n",
       "      <th>color_062_068</th>\n",
       "      <th>color_068_074</th>\n",
       "      <th>color_074_08</th>\n",
       "      <th>...</th>\n",
       "      <th>geometric_42_002_4</th>\n",
       "      <th>geometric_84_004_8</th>\n",
       "      <th>geometric_126_006_12</th>\n",
       "      <th>geometric_168_008_16</th>\n",
       "      <th>geometric_2010_01_20</th>\n",
       "      <th>geometric_2412_012_24</th>\n",
       "      <th>geometric_2814_014_28</th>\n",
       "      <th>geometric_3216_016_32</th>\n",
       "      <th>geometric_3618_018_36</th>\n",
       "      <th>geometric_4020_02_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T15:25:44.671626Z",
     "start_time": "2025-07-09T15:25:44.666920Z"
    }
   },
   "cell_type": "code",
   "source": "(out[1]==1).sum()",
   "id": "79cbc7ed8c70b3a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(392)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T15:02:01.716071Z",
     "start_time": "2025-07-09T15:02:01.711073Z"
    }
   },
   "cell_type": "code",
   "source": "(out[0]==0)*(out[1]==1)",
   "id": "7c5598ca2e1c276e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False, False, False, False, False,\n",
       "        True,  True, False, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False,  True,  True,  True, False,  True,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "        True,  True, False, False, False,  True,  True, False, False,\n",
       "        True, False, False,  True,  True, False, False,  True, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "       False, False,  True,  True, False,  True,  True, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "        True,  True, False,  True, False,  True, False, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "       False,  True,  True,  True, False,  True, False, False,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True, False,  True,  True, False, False,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False,  True, False,  True,  True, False,\n",
       "        True, False, False, False, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "       False,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True, False, False,  True,  True,\n",
       "       False,  True,  True,  True,  True, False, False, False, False,\n",
       "        True, False,  True,  True,  True, False, False,  True, False,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True, False, False,\n",
       "       False, False,  True, False,  True,  True, False,  True, False,\n",
       "        True, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "       False,  True, False, False, False,  True, False,  True, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True,  True, False, False, False,\n",
       "        True,  True, False,  True, False, False, False, False,  True,\n",
       "       False, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False, False,  True, False, False,  True,  True,  True,\n",
       "       False,  True,  True, False,  True, False, False, False,  True,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "       False, False,  True, False, False,  True, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True, False,  True,  True,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True,  True, False,  True,  True, False, False, False, False,\n",
       "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "       False,  True, False,  True, False,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "       False, False,  True,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True, False, False,\n",
       "        True, False, False, False, False, False,  True,  True,  True,\n",
       "       False,  True, False, False,  True, False,  True, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True,  True,  True, False,  True, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True, False,  True, False,  True, False, False,\n",
       "       False, False,  True, False, False,  True, False, False,  True,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False, False,  True,  True, False,  True, False, False,\n",
       "        True,  True, False, False,  True, False,  True, False, False,\n",
       "        True,  True,  True,  True, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True, False, False,  True, False,\n",
       "        True, False,  True,  True, False, False,  True,  True, False,\n",
       "       False,  True,  True, False, False,  True,  True, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False,  True, False,  True,  True,  True, False,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot figure comparing experiments\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for exp in ['supervised', 'unsupervised']:\n",
    "    dataset='MVTEC'\n",
    "    # Put together accuracy list for each experiment for plotting\n",
    "    acc_list = []\n",
    "\n",
    "    # For MVTEC\n",
    "    if dataset == \"MVTEC\":\n",
    "        for task in task_acc[dataset][exp].keys():\n",
    "            acc_list.append(task_acc[dataset][exp][task])\n",
    "        fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                 name=f\"{exp}\"))\n",
    "    # For MTD\n",
    "    elif dataset == \"MTD\":\n",
    "        # Iterate through each data aug type\n",
    "        for aug in ['color', 'blur', 'geometric']:\n",
    "            acc_list = []\n",
    "            for task in task_acc[dataset][exp].keys():\n",
    "                if task.startswith(aug):\n",
    "                    acc_list.append(task_acc[dataset][exp][task])\n",
    "            fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                     name=f\"MTD-{exp}-{aug}\"))\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"DNE Accuracy on all Previous Tasks, MVTEC\",\n",
    "                  xaxis_title=\"Task Number\",\n",
    "                  yaxis_title=\"Accuracy on all Testing sets of previous tasks\")\n",
    "fig.show()"
   ],
   "id": "43ede93edf96922b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot figure comparing experiments\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for dataset in [\"MVTEC\", \"MTD\"]:\n",
    "    exp='supervised'\n",
    "    # Put together accuracy list for each experiment for plotting\n",
    "    acc_list = []\n",
    "    \n",
    "    # For MVTEC\n",
    "    if dataset == \"MVTEC\":\n",
    "        for task in task_acc[dataset][exp].keys():\n",
    "            acc_list.append(task_acc[dataset][exp][task])\n",
    "        fig.add_trace(go.Scatter(y=acc_list, mode='lines', \n",
    "                                 name=f\"MVTEC-{exp}\"))\n",
    "    # For MTD\n",
    "    elif dataset == \"MTD\":\n",
    "        # Iterate through each data aug type\n",
    "        for aug in ['color', 'blur', 'geometric']:\n",
    "            acc_list = []\n",
    "            for task in task_acc[dataset][exp].keys():\n",
    "                if task.startswith(aug):\n",
    "                    acc_list.append(task_acc[dataset][exp][task])\n",
    "            fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                     name=f\"MTD-{exp}-{aug}\"))\n",
    "                \n",
    "        \n",
    "fig.update_layout(title=\"DNE Accuracy on all Previous Tasks, Supervised Training\",\n",
    "                  xaxis_title=\"Task Number\",\n",
    "                  yaxis_title=\"Accuracy on all Testing sets of previous tasks\")\n",
    "fig.show()"
   ],
   "id": "1070ddebd5b95ca8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot figure comparing experiments\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for dataset in [\"MVTEC\", \"MTD\"]:\n",
    "    exp='unsupervised'\n",
    "    # Put together accuracy list for each experiment for plotting\n",
    "    acc_list = []\n",
    "\n",
    "    # For MVTEC\n",
    "    if dataset == \"MVTEC\":\n",
    "        for task in task_acc[dataset][exp].keys():\n",
    "            acc_list.append(task_acc[dataset][exp][task])\n",
    "        fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                 name=f\"MVTEC-{exp}\"))\n",
    "    # For MTD\n",
    "    elif dataset == \"MTD\":\n",
    "        # Iterate through each data aug type\n",
    "        for aug in ['color', 'blur', 'geometric']:\n",
    "            acc_list = []\n",
    "            for task in task_acc[dataset][exp].keys():\n",
    "                if task.startswith(aug):\n",
    "                    acc_list.append(task_acc[dataset][exp][task])\n",
    "            fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                     name=f\"MTD-{exp}-{aug}\"))\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"DNE Accuracy on all Previous Tasks, Unupervised Training\",\n",
    "                  xaxis_title=\"Task Number\",\n",
    "                  yaxis_title=\"Accuracy on all Testing sets of previous tasks\")\n",
    "fig.show()"
   ],
   "id": "8d9cc523b28b6670",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "task_spec = task_data.copy()\n",
    "for dataset in task_data.keys():\n",
    "    for exp in task_data[dataset].keys():\n",
    "        for task in task_data[dataset][exp].keys():\n",
    "            (preds, labels) = task_data[dataset][exp][task]\n",
    "            tn = 0\n",
    "            fp = 0\n",
    "            for i in range(len(preds)):\n",
    "                # 1 is anomaly\n",
    "                if labels[i]==1:\n",
    "                    if preds[i]==1: # tn\n",
    "                        tn += 1\n",
    "                    else:\n",
    "                        fp += 1\n",
    "                        \n",
    "            specificity = tn / (tn + fp)\n",
    "            task_spec[dataset][exp][task] = specificity\n",
    "task_spec"
   ],
   "id": "e9dea28001aa09cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot figure comparing experiments\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for exp in ['supervised', 'unsupervised']:\n",
    "    dataset='MVTEC'\n",
    "    # Put together accuracy list for each experiment for plotting\n",
    "    acc_list = []\n",
    "\n",
    "    # For MVTEC\n",
    "    if dataset == \"MVTEC\":\n",
    "        for task in task_spec[dataset][exp].keys():\n",
    "            acc_list.append(task_spec[dataset][exp][task])\n",
    "        fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                 name=f\"{exp}\"))\n",
    "    # For MTD\n",
    "    elif dataset == \"MTD\":\n",
    "        # Iterate through each data aug type\n",
    "        for aug in ['color', 'blur', 'geometric']:\n",
    "            acc_list = []\n",
    "            for task in task_spec[dataset][exp].keys():\n",
    "                if task.startswith(aug):\n",
    "                    acc_list.append(task_spec[dataset][exp][task])\n",
    "            fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                     name=f\"MTD-{exp}-{aug}\"))\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"DNE Sensitivity on all Previous Tasks, MVTEC\",\n",
    "                  xaxis_title=\"Task Number\",\n",
    "                  yaxis_title=\"Sensitivity on all Testing sets of previous tasks\")\n",
    "fig.show()"
   ],
   "id": "be51dc1d63cd1ced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot figure comparing experiments\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for dataset in [\"MVTEC\", \"MTD\"]:\n",
    "    exp='supervised'\n",
    "    # Put together accuracy list for each experiment for plotting\n",
    "    acc_list = []\n",
    "\n",
    "    # For MVTEC\n",
    "    if dataset == \"MVTEC\":\n",
    "        for task in task_spec[dataset][exp].keys():\n",
    "            acc_list.append(task_spec[dataset][exp][task])\n",
    "        fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                 name=f\"MVTEC-{exp}\"))\n",
    "    # For MTD\n",
    "    elif dataset == \"MTD\":\n",
    "        # Iterate through each data aug type\n",
    "        for aug in ['color', 'blur', 'geometric']:\n",
    "            acc_list = []\n",
    "            for task in task_spec[dataset][exp].keys():\n",
    "                if task.startswith(aug):\n",
    "                    acc_list.append(task_spec[dataset][exp][task])\n",
    "            fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                     name=f\"MTD-{exp}-{aug}\"))\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"DNE Sensitivity on all Previous Tasks, Supervised Training\",\n",
    "                  xaxis_title=\"Task Number\",\n",
    "                  yaxis_title=\"Sensitivity on all Testing sets of previous tasks\")\n",
    "fig.show()"
   ],
   "id": "d871be780d3dbf8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot figure comparing experiments\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for dataset in [\"MVTEC\", \"MTD\"]:\n",
    "    exp='unsupervised'\n",
    "    # Put together accuracy list for each experiment for plotting\n",
    "    acc_list = []\n",
    "\n",
    "    # For MVTEC\n",
    "    if dataset == \"MVTEC\":\n",
    "        for task in task_spec[dataset][exp].keys():\n",
    "            acc_list.append(task_spec[dataset][exp][task])\n",
    "        fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                 name=f\"MVTEC-{exp}\"))\n",
    "    # For MTD\n",
    "    elif dataset == \"MTD\":\n",
    "        # Iterate through each data aug type\n",
    "        for aug in ['color', 'blur', 'geometric']:\n",
    "            acc_list = []\n",
    "            for task in task_spec[dataset][exp].keys():\n",
    "                if task.startswith(aug):\n",
    "                    acc_list.append(task_spec[dataset][exp][task])\n",
    "            fig.add_trace(go.Scatter(y=acc_list, mode='lines',\n",
    "                                     name=f\"MTD-{exp}-{aug}\"))\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"DNE Sensitivity on all Previous Tasks, Unupervised Training\",\n",
    "                  xaxis_title=\"Task Number\",\n",
    "                  yaxis_title=\"Sensitivity on all Testing sets of previous tasks\")\n",
    "fig.show()"
   ],
   "id": "7c0b3b4c214ff9ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.count_nonzero((preds+labels)==2)",
   "id": "9a2bb026f6590b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e3c2a90983318ee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
