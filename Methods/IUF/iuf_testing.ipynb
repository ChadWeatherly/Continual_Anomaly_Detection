{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Incremental Unified Framework (IUF) Testing\n",
    "\n",
    "We want to test each component and module in isolation to make sure it's working properly\n",
    "\n",
    "_TODO:_\n",
    "1. Go through ViT code and understand unique implementation\n",
    "2. Update to include modules for creating Discriminator, Encoder, & Decoder\n",
    "3. Check for paper/code for architecture or hyperparams match our implementation (num_heads, dim, etc)\n",
    "4. Latent Space Regularization\n",
    "5. Gradient Update Regularization\n"
   ],
   "id": "79cd97f4118f2f3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:00:15.435104Z",
     "start_time": "2025-06-17T16:00:13.445012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import einops as ein\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from Methods import BaseAnomalyDetector\n",
    "from Methods.IUF.ViT import MultiHeadSelfAttention, ViTBlock, ViT\n",
    "from Methods.IUF.utils.discriminator import Discriminator\n",
    "from Methods.IUF.utils.encoder import Encoder\n",
    "from Methods.IUF.utils.decoder import Decoder"
   ],
   "id": "d72cdfd011c9690b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:00:17.831224Z",
     "start_time": "2025-06-17T16:00:16.036029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Starting to put together an IUF pipeline for testing\n",
    "class IUF(BaseAnomalyDetector):\n",
    "    \"\"\"\n",
    "    Complete IUF Module\n",
    "\n",
    "    We have one ViT class that we build on,\n",
    "    From there, we will add methods to create the discriminator, encoder, and decoder.\n",
    "\n",
    "    Algorithm Notes:\n",
    "\n",
    "        ViT\n",
    "        - Added positional encoding to the tokens\n",
    "        - Changed BatchNorm to LayerNorm and ReLU to GELU, in accordance with the ViT paper\n",
    "        - I noticed that in their Multi-head attention, the authors only work on row-wise attention to simplify their computations, so I am going to operate on patches, as the multiplication is too large.\n",
    "        - Batch size needs to maybe be larger than the embedding dimension?\n",
    "\n",
    "        Loss function consists of the following components:\n",
    "        - Reconstruction error = abs(x_recon - x)\n",
    "        - Discriminator error = CrossEntropy(discrim_output, true label)\n",
    "        - Singular Value error = sum(singular_vals from t -> C), from SVD(M_hat),\n",
    "                                where t is a hyperparameter and C is the total number of singular values.\n",
    "        Each component is weighted by a corresponding lambda, where\n",
    "        - lamba1 = 1\n",
    "        - lamba2 = 0.5\n",
    "        - lamba3 = 1-10\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # oasa_features = list of length num_layers,\n",
    "        # where each item is a tensor of size (B x L x E)\n",
    "\n",
    "        # d_out is of size (B x num_classes)\n",
    "        oasa_features, d_out = self.discriminator(x, return_features=True)\n",
    "\n",
    "        z, u, s, v = self.encoder(x, oasa_features)\n",
    "        # z = latent features, (B x L x E)\n",
    "        # u, s, v from SVD\n",
    "        # u, (B x B)\n",
    "        # S, (B/C), whichever is smaller\n",
    "        # V, (C x C), C = channels/embed_dim\n",
    "\n",
    "        x_recon = self.decoder(z)\n",
    "\n",
    "        return x_recon\n",
    "\n",
    "iuf = IUF()\n",
    "dummy = torch.rand(8, 3, 224, 224)\n",
    "x_recon = iuf(dummy)"
   ],
   "id": "1acfb805f3b2f740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:00:18.226910Z",
     "start_time": "2025-06-17T16:00:18.218583Z"
    }
   },
   "cell_type": "code",
   "source": "x_recon.shape",
   "id": "71a4199ecdbad2b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 196, 196])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:05:21.512223Z",
     "start_time": "2025-06-17T15:05:21.506896Z"
    }
   },
   "cell_type": "code",
   "source": "s",
   "id": "b8c887afcd5a9b11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.6624,  0.4635,  0.4140,  0.2827,  0.2293,  0.2035,  0.1863,  0.1360],\n",
       "       grad_fn=<LinalgSvdBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:32:07.601588Z",
     "start_time": "2025-06-16T15:32:07.598116Z"
    }
   },
   "cell_type": "code",
   "source": ".049201**2",
   "id": "eb1de98f4d804d18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002420738401"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89c90a0734eeeec8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
